# PhilogicAI - Schnellstart Anleitung

## Ãœbersicht

PhilogicAI verbindet deine lokale AI (llama.cpp) mit der Production Website Ã¼ber Cloudflare Tunnel.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Cloudflare Pages       â”‚
â”‚  (philogichub.com)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚ HTTPS + Auth Token
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Cloudflare Tunnel      â”‚
â”‚  ai.philogichub.com     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚ Localhost only
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Flask Server           â”‚
â”‚  localhost:8000         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
            â”‚
            â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  llama.cpp              â”‚
â”‚  + Qwen3-14B Model      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸš€ Schnellstart (5 Schritte)

### 1. Auth Token generieren

```powershell
python -c "import secrets; print(secrets.token_urlsafe(32))"
```

Kopiere den generierten Token - du brauchst ihn 3x:
- Im Server
- In .env.local
- In Cloudflare Pages

### 2. Python Dependencies installieren

```powershell
cd C:\philogic-ai
pip install flask flask-cors
```

### 3. Server Datei kopieren

```powershell
# Aus philogichub Ordner
copy philogic-ai-server.py C:\philogic-ai\server.py

# Ã–ffne C:\philogic-ai\server.py und passe Pfade an:
# - LLAMA_CPP_PATH (Zeile 23)
# - MODEL_PATH (Zeile 24)
```

### 4. Cloudflare Tunnel Setup

```powershell
# Im philogichub Ordner
.\setup-cloudflare-tunnel.ps1

# Script fÃ¼hrt dich durch:
# - cloudflared Download
# - Cloudflare Login (Browser Ã¶ffnet sich)
# - Tunnel Erstellung
# - DNS Setup
```

### 5. Starte Services

**Terminal 1 - PhilogicAI Server:**
```powershell
cd C:\philogic-ai
$env:PHILOGIC_AUTH_TOKEN = "DEIN_TOKEN_VON_SCHRITT_1"
python server.py
```

**Terminal 2 - Cloudflare Tunnel:**
```powershell
cd C:\philogic-ai
.\start-tunnel.bat
```

**Terminal 3 - Next.js Dev Server:**
```powershell
cd C:\Philip\myapps\philogichub
npm run dev
```

### 6. Teste lokal

Ã–ffne http://localhost:3000 â†’ Klicke auf Chat-Button (unten rechts) â†’ Teste eine Frage!

---

## ğŸ”§ Production Deployment

### Cloudflare Pages Environment Variables

In deinem Cloudflare Pages Dashboard:

1. Gehe zu: Settings â†’ Environment Variables
2. FÃ¼ge hinzu:
   ```
   PHILOGIC_AI_URL=https://ai.philogichub.com/api/chat
   PHILOGIC_AUTH_TOKEN=<DEIN_TOKEN>
   ```
3. Deploy neu

### Wichtig: Tunnel muss laufen!

Der Cloudflare Tunnel muss auf deinem PC laufen, damit Production funktioniert.

**Option A: Terminal offen lassen**
```powershell
cd C:\philogic-ai
.\start-tunnel.bat
```

**Option B: Windows Service installieren**
```powershell
cd C:\philogic-ai
.\cloudflared.exe service install
```

---

## ğŸ”’ Sicherheit

âœ… **Auth Token** - Nur autorisierte Requests werden verarbeitet
âœ… **Localhost only** - Server nicht direkt erreichbar von auÃŸen
âœ… **Cloudflare Tunnel** - End-to-End verschlÃ¼sselt, keine offenen Ports
âœ… **Keine Logs** - Conversation History wird NICHT gespeichert

### ZusÃ¤tzliche Sicherheit (Optional)

**IP Whitelist in Cloudflare:**

1. Gehe zu Cloudflare Dashboard
2. WÃ¤hle deine Domain
3. Security â†’ WAF
4. Create Rule:
   - Name: "PhilogicAI IP Whitelist"
   - Field: Hostname
   - Operator: equals
   - Value: ai.philogichub.com
   - Action: Block
   - Expression: `(ip.src ne YOUR_OFFICE_IP)`

**Email Authentication (Cloudflare Zero Trust):**

1. Cloudflare Dashboard â†’ Zero Trust
2. Access â†’ Applications
3. Add application:
   - Type: Self-hosted
   - Domain: ai.philogichub.com
   - Policy: Email authentication
   - Allowed emails: deine@firmen-emails.com

---

## ğŸ® Model Konfiguration

### GPU Nutzung optimieren

In `C:\philogic-ai\server.py` (Zeile 30):

```python
GPU_LAYERS = 32  # ErhÃ¶he fÃ¼r mehr VRAM usage
```

**Empfehlungen:**
- 8GB VRAM: `GPU_LAYERS = 24`
- 12GB VRAM: `GPU_LAYERS = 32`
- 16GB+ VRAM: `GPU_LAYERS = 40`
- Nur CPU: `GPU_LAYERS = 0`

### Anderes Model verwenden

Ã„ndere in `server.py` (Zeile 24):

```python
MODEL_PATH = r"C:\philogic-ai\models\DEIN-MODEL.gguf"
```

**Empfohlene Models:**
- Qwen3-14B-Q5_K_M.gguf (9.8 GB) - Beste Balance
- Qwen3-32B-Q4_K_M.gguf (19.2 GB) - Mehr QualitÃ¤t
- Qwen3-7B-Q5_K_M.gguf (5.4 GB) - Schneller

---

## ğŸ“Š Monitoring

### Server Status prÃ¼fen

```powershell
# Health Check
curl http://localhost:8000/health

# Tunnel Status
cd C:\philogic-ai
.\cloudflared.exe tunnel info philogic-ai-tunnel

# Tunnel List
.\cloudflared.exe tunnel list
```

### Logs ansehen

- **Server Logs:** Terminal 1 wo `python server.py` lÃ¤uft
- **Tunnel Logs:** Terminal 2 wo Tunnel lÃ¤uft
- **Next.js Logs:** Terminal 3 Dev Server

---

## ğŸ› Troubleshooting

### Problem: "Model not found"

```powershell
# PrÃ¼fe ob Model existiert
dir C:\philogic-ai\models\

# Passe Pfad in server.py an (Zeile 24)
```

### Problem: "llama-cli.exe not found"

```powershell
# PrÃ¼fe ob llama.cpp kompiliert ist
dir C:\philogic-ai\llama.cpp\build\bin\Release\

# Falls nicht, kompiliere:
cd C:\philogic-ai\llama.cpp
cmake -B build
cmake --build build --config Release
```

### Problem: Tunnel verbindet nicht

```powershell
# Stoppe Tunnel
# DrÃ¼cke CTRL+C im Tunnel Terminal

# Starte neu
cd C:\philogic-ai
.\cloudflared.exe tunnel --config cloudflared-config.yml run philogic-ai-tunnel

# PrÃ¼fe DNS
nslookup ai.philogichub.com
```

### Problem: "Unauthorized" im Chat

1. PrÃ¼fe ob Token identisch ist:
   - `C:\philogic-ai\server.py` (Zeile 22)
   - `.env.local` im philogichub Ordner
   - Cloudflare Pages Environment Variables

2. Starte Server neu nach Token-Ã„nderung

### Problem: Langsame Inference

1. ErhÃ¶he GPU Layers: `GPU_LAYERS = 40` in server.py
2. Reduziere Max Tokens: `MAX_TOKENS = 256`
3. Verwende kleineres Model (Q4 statt Q5)

---

## ğŸ“ Dateien Ãœbersicht

```
C:\philogic-ai\
â”œâ”€â”€ server.py                    # Flask Server (kopiert von philogic-ai-server.py)
â”œâ”€â”€ cloudflared.exe              # Cloudflare Tunnel binary
â”œâ”€â”€ cloudflared-config.yml       # Tunnel Konfiguration
â”œâ”€â”€ start-tunnel.bat             # Tunnel Startup Script
â”œâ”€â”€ llama.cpp\                   # llama.cpp Installation
â”‚   â””â”€â”€ build\bin\Release\
â”‚       â””â”€â”€ llama-cli.exe
â””â”€â”€ models\
    â””â”€â”€ Qwen3-14B-Q5_K_M.gguf

C:\Philip\myapps\philogichub\
â”œâ”€â”€ .env.local                   # Lokale Environment Variables
â”œâ”€â”€ philogic-ai-server.py        # Server Source (zu kopieren)
â”œâ”€â”€ start-philogic-ai.bat        # Server Startup Script
â”œâ”€â”€ setup-cloudflare-tunnel.ps1  # Tunnel Setup Script
â”œâ”€â”€ PHILOGIC_AI_SETUP.md         # AusfÃ¼hrliche Doku
â””â”€â”€ app\
    â”œâ”€â”€ components\
    â”‚   â””â”€â”€ PhilogicAIChat.tsx   # Chat UI Component
    â””â”€â”€ api\philogic-ai\chat\
        â””â”€â”€ route.ts             # API Proxy Route
```

---

## âœ… Checkliste

- [ ] Python installiert (3.9+)
- [ ] Flask installiert (`pip install flask flask-cors`)
- [ ] llama.cpp kompiliert
- [ ] Model heruntergeladen (Qwen3-14B-Q5_K_M.gguf)
- [ ] Auth Token generiert
- [ ] `server.py` Pfade angepasst
- [ ] Cloudflare Tunnel Setup durchgefÃ¼hrt
- [ ] `.env.local` mit Token konfiguriert
- [ ] Server lÃ¤uft (Terminal 1)
- [ ] Tunnel lÃ¤uft (Terminal 2)
- [ ] Next.js lÃ¤uft (Terminal 3)
- [ ] Lokaler Test erfolgreich
- [ ] Cloudflare Pages Environment Variables gesetzt
- [ ] Production Test erfolgreich

---

## ğŸ†˜ Support

Bei Problemen prÃ¼fe:
1. Alle 3 Services laufen (Server, Tunnel, Next.js)
2. Token ist Ã¼berall identisch
3. Pfade in server.py sind korrekt
4. Model existiert und ist nicht korrupt
5. Firewall blockiert nicht Port 8000 (localhost)

**Logs prÃ¼fen:**
```powershell
# Server Ausgabe im Terminal 1
# Tunnel Ausgabe im Terminal 2
# Browser Console (F12) fÃ¼r Frontend-Fehler
```
